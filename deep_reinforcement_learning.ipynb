{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ETFs = [\"159920.SZ\",\"510900.SH\",\"518880.SH\",\"511010.SH\",\"159915.SZ\",\"510050.SH\",\"510300.SH\",\"510500.SH\"]\n",
    "\n",
    "modelInitialLookbackWindowSize = 400\n",
    "lookbackNumWindowsForSignals = 20\n",
    "\n",
    "outputDir = \"/Users/kuen/Desktop/RL/Output/\"\n",
    "featureDir = \"/Users/kuen/Desktop/RL/Features/\"\n",
    "\n",
    "readInCols = ['Date', 'vwap', 'todayOpen', 'zt', 'zt0', 'zt1', 'zt2', 'zt3', 'zt4']\n",
    "\n",
    "features = {}\n",
    "\n",
    "for ticker in ETFs:\n",
    "    features[ticker] = pd.read_csv(featureDir + 'features_' + ticker + '.csv', usecols=readInCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build models for individual ETFs with tensorflow\n",
    "# set the right device for computation\n",
    "import os\n",
    "os.environ['CUDA_DEVIDE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # only use gpu 0\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any 0,1,2\n",
    "\n",
    "import tensorflow as tf\n",
    "# check if gpu is used correctly\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs \n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "pastDays = modelInitialLookbackWindowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_stepsArray = [20, 200] # T: length of recurrent cells\n",
    "n_inputs = 5 # number of input features, zt0 - zt4\n",
    "n_hidden1 = 128\n",
    "n_hidden2 = 128\n",
    "n_hidden3 = 128\n",
    "n_hidden4 = 16\n",
    "n_neurons = 1 # number of recurrent neurons\n",
    "n_outputs = 1 # output dimension\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 200\n",
    "\n",
    "c = 0.0002 # transaction fee level\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # iterate through all ETF tickers\n",
    "for ticker in ETFs:\n",
    "    featureData = features[ticker]\n",
    "    # iterate through days\n",
    "    dates = featureData.Date\n",
    "    date_index = np.unique(dates)\n",
    "    date_num = date_index.size\n",
    "    \n",
    "    for n_steps in n_stepsArray:\n",
    "        cols = ['ticker','date','delta','nextCloseToOpen','nextDayOpen','TR','SR','nDCtoCPnL','nDCtoCPnLMinusTC','nDCtoCCumuPnLMinusTC']\n",
    "        outputFile = pd.DataFrame(columns = cols)\n",
    "        print('date_num='+str(date_num))\n",
    "        print('pastDays='+str(pastDays))\n",
    "        cumuPnL = 0\n",
    "        cumuPnLMinusTC = 0\n",
    "        for i in range(date_num - pastDays - 1): # from 0 to data_num - pastDays - 1\n",
    "            trainDates = [date_index[i]] # i = 0, the first trading day.\n",
    "            for j in range(i+1, i+pastDays): # [this for loop is unnecessary, change it in the next version]\n",
    "                trainDates.append(date_index[j])\n",
    "            \n",
    "            dataPd = featureData[featureData.Date.isin(trainDates)]\n",
    "            dataNextD = featureData[featureData.Date == date_index[i+pastDays]]\n",
    "            \n",
    "            # prepare data\n",
    "            startIdx = 4\n",
    "            F_train_all = dataPd.iloc[:, startIdx:(n_inputs+startIdx)].values\n",
    "            z_train_all = dataPd.zt.values \n",
    "            p_train_all = dataPd.todayOpen.values\n",
    "            \n",
    "            F_train = F_train_all[:int(len(dataPd)/n_steps)*n_steps, :]\n",
    "            z_train = z_train_all[:int(len(dataPd)/n_steps)*n_steps]\n",
    "            p_train = p_train_all[:int(len(dataPd)/n_steps)]\n",
    "            \n",
    "            # build computation graph\n",
    "            reset_graph()\n",
    "            \n",
    "            f = tf.placeholder(tf.float32, shape=(None, n_inputs),name='input')\n",
    "            z = tf.placeholder(tf.float32, [None, n_steps, n_outputs], name='z')\n",
    "            p = tf.placeholder(tf.float32, [None, n_steps, n_outputs], name='p')\n",
    "            \n",
    "            with tf.name_scope('DNN'):\n",
    "                hidden1 = tf.layers.dense(f, n_hidden1, activation=tf.nn.selu,name='hidden1')\n",
    "                hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name='hidden2')\n",
    "                hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.selu, name='hideen3')\n",
    "                hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.selu, name='hidden4')\n",
    "            \n",
    "            F = tf.reshape(hidden4, [-1, n_steps, n_hidden4])\n",
    "            \n",
    "            cell = tf.contrib.rnn.OutputProjectionWrapper(tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=None,name='rnn'), output_size=n_outputs)\n",
    "            \n",
    "            deltaTemp, states = tf.nn.dynamic_rnn(cell, F, dtype=tf.float32)\n",
    "            delta = tf.nn.relu(deltaTemp, name='deltaCalc')\n",
    "            \n",
    "            R = tf.pad(delta[:, :(n_steps-1), :] * z[:,1:(n_steps), :] - \n",
    "                       tf.abs(delta[:, 1:n_steps,:] - delta[:,:(n_steps-1),:])*\n",
    "                       p[:,1:n_steps] * c, \n",
    "                       paddings = [[0,0],\n",
    "                                   [1,0],\n",
    "                                   [0,0]])\n",
    "            \n",
    "            U = tf.reduce_mean(tf.reduce_sum(R, axis=1))\n",
    "            \n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "            \n",
    "            grad = optimizer.compute_gradients(-U)\n",
    "            apply_grad = optimizer.apply_gradients(grad)\n",
    "            \n",
    "            # Objective function\n",
    "            TR = tf.reduce_sum(R)\n",
    "            SR = tf.reduce_sum(R)/ (tf.sqrt(tf.nn.moments(tf.reshape(R,[-1]),\n",
    "                                                         axes=0)[1])+1e-10)*np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
